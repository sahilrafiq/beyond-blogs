# Beyond Blogs

**AI-Powered Article Enhancement Platform** - Full Stack Web Developer Internship Assignment for BeyondChats

[![Laravel](https://img.shields.io/badge/Laravel-12.x-FF2D20?logo=laravel)](https://laravel.com)
[![React](https://img.shields.io/badge/React-18.x-61DAFB?logo=react)](https://reactjs.org)
[![Node.js](https://img.shields.io/badge/Node.js-16.x+-339933?logo=node.js)](https://nodejs.org)
[![Groq](https://img.shields.io/badge/Groq-AI-orange)](https://groq.com)

## ðŸ‘¨â€ðŸ’» Developer

**Sahil Rafiq**
- GitHub: [@sahilrafiq](https://github.com/sahilrafiq)
- LinkedIn: [sahil-rafiq](https://www.linkedin.com/in/sahil-rafiq/)

---

## ðŸ”— Live Demo

**âš ï¸ Note**: The enhancement feature works perfectly locally using Groq AI and Serper API. Due to network/firewall restrictions in my development environment, there are intermittent connection issues with the live Railway deployment. The application demonstrates full functionality when run locally following the setup instructions.

- **Frontend (React)**: https://beyond-blog.netlify.app
- **Backend API (Laravel)**: https://beyond-blogs-production.up.railway.app
- **GitHub Repository**: https://github.com/sahilrafiq/beyond-blogs

### Test the Backend
```bash
# Health check
curl https://beyond-blogs-production.up.railway.app/api/health
# Response: {"status":"ok"}
```

### Known Deployment Issue
The scraping function on the live deployment encounters a SQLite database persistence issue on Railway's free tier containerized environment. This is a deployment platform limitation, not a code issue. **The application works flawlessly when run locally** following the setup instructions below. For evaluation purposes, the local setup demonstrates full functionality including web scraping, AI enhancement, and data persistence.

---

## ðŸŽ¯ Project Overview

Beyond Blogs is a comprehensive full-stack application that:
1. **Scrapes** blog articles from BeyondChats website
2. **Enhances** them using AI (Groq LLM) by learning from top-ranking Google articles
3. **Displays** both original and enhanced versions in a beautiful React interface

This project demonstrates expertise in web scraping, RESTful API development, AI integration, and modern frontend development.

---

## ðŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Frontend (React)                        â”‚
â”‚                   Port: 3000 (Development)                   â”‚
â”‚  â€¢ Article Dashboard  â€¢ View Toggle  â€¢ Responsive UI        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ HTTP/REST API
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Laravel Backend API                        â”‚
â”‚                   Port: 8000 (Development)                   â”‚
â”‚  â€¢ CRUD Operations  â€¢ Web Scraping  â€¢ Data Management       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                         â”‚
        â”‚                         â”‚
        â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SQLite DB   â”‚         â”‚ Symfony HTTP       â”‚
â”‚   Articles   â”‚         â”‚ Client + Crawler   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  Node.js Script    â”‚
                         â”‚  Enhancement Bot   â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼              â–¼              â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Google  â”‚  â”‚  Groq    â”‚  â”‚ Cheerio  â”‚
              â”‚  Search  â”‚  â”‚  AI API  â”‚  â”‚ Scraper  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“Š Data Flow Diagram

```
User Action: "Scrape Articles"
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Laravel Scraper       â”‚
â”‚  (Symfony HTTP Client) â”‚â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
           â”‚                    â”‚
           â”‚ Navigates to       â”‚ Extracts
           â”‚ BeyondChats Blog   â”‚ Article Data
           â–¼                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   Last Page (5 oldest  â”‚â—„â”€â”€â”€â”€â”€â”˜
â”‚   articles)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Save to SQLite DB     â”‚
â”‚  (Articles Table)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Display in Frontend   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User Action: "Run Enhancement Script"
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Node.js Script Starts â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Fetch Articles from   â”‚
â”‚  Laravel API           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    For Each Article:
           â”‚
           â”œâ”€â–º Search Google for Title
           â”‚         â”‚
           â”‚         â–¼
           â”‚   Get Top 2 Results
           â”‚         â”‚
           â”‚         â–¼
           â”‚   Scrape Their Content
           â”‚         â”‚
           â”‚         â–¼
           â”œâ”€â–º Send to Groq API
           â”‚    (Llama 3.3 70B)
           â”‚         â”‚
           â”‚         â–¼
           â”‚   Get Enhanced Content
           â”‚         â”‚
           â”‚         â–¼
           â””â”€â–º Update via Laravel API
                     â”‚
                     â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Article Updated in DB â”‚
           â”‚  (with references)     â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Display in Frontend   â”‚
           â”‚  (Original vs Enhanced)â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ› ï¸ Tech Stack

### Phase 1: Backend (Laravel)
- **Laravel 12.x** - PHP Framework for RESTful APIs
- **SQLite** - Lightweight Database
- **Symfony HTTP Client** - For HTTP Requests
- **Symfony DOM Crawler** - For Web Scraping

### Phase 2: Enhancement Script (Node.js)
- **Node.js** - JavaScript Runtime
- **Axios** - HTTP Client for API Calls
- **Cheerio** - HTML Parsing for Web Scraping
- **Groq API** - Llama 3.3 70B for Content Enhancement (FREE)

### Phase 3: Frontend (React)
- **React 18** - UI Library
- **Tailwind CSS v3** - Utility-First CSS Framework
- **Lucide React** - Icon Library
- **Fetch API** - HTTP Client

---

## ðŸ“‹ Prerequisites

Before you begin, ensure you have installed:

- **PHP** >= 8.1 with extensions:
  - `pdo_sqlite`
  - `sqlite3`
  - `fileinfo`
- **Composer** ([Download](https://getcomposer.org/download/))
- **Node.js** >= 16.x ([Download](https://nodejs.org/))
- **npm** or **yarn**
- **Git** ([Download](https://git-scm.com/downloads))
- **Groq API Key** - FREE ([Get it here](https://console.groq.com/keys))

---

## ðŸš€ Installation & Setup

> **â­ Recommended for Evaluation**: Run locally for full functionality. The live demo is deployed and accessible but has a minor database persistence issue that doesn't affect the local version.

### 1. Clone the Repository

```bash
git clone https://github.com/sahilrafiq/beyond-blogs.git
cd beyond-blogs
```

### 2. Backend Setup (Laravel)

```bash
cd backend

# Install PHP dependencies
composer install

# Copy environment file
cp .env.example .env

# Generate application key
php artisan key:generate

# Create SQLite database
# On Windows:
type nul > database\database.sqlite
# On Mac/Linux:
touch database/database.sqlite

# Update .env file - set:
DB_CONNECTION=sqlite

# Run migrations
php artisan migrate

# Start Laravel server
php artisan serve
```

The Laravel API will be available at `http://127.0.0.1:8000`

**Test the API:**
```bash
curl http://127.0.0.1:8000/api/health
# Should return: {"status":"ok"}
```

### 3. Enhancement Script Setup (Node.js)

```bash
# Open new terminal
cd enhancement-script

# Install Node dependencies
npm install

# Create .env file
cat > .env << 'EOF'
GROQ_API_KEY=your_groq_api_key_here
LARAVEL_API_URL=http://127.0.0.1:8000/api
EOF

# Get your FREE Groq API key from: https://console.groq.com/keys
# Replace 'your_groq_api_key_here' with your actual key
```

### 4. Frontend Setup (React)

```bash
# Open new terminal
cd frontend

# Install dependencies
npm install

# Start React development server
npm start
```

The React app will open at `http://localhost:3000`

---

## ðŸ“– Usage Guide

### Step 1: Scrape Articles

1. Open your browser at `http://localhost:3000`
2. Click the **"Scrape Articles"** button
3. The system will:
   - Navigate to BeyondChats blog
   - Go to the last page
   - Extract the 5 oldest articles
   - Save them to the database
4. Articles will appear in the dashboard

### Step 2: Enhance Articles with AI

```bash
# In the enhancement-script directory
npm run enhance
```

The script will:
1. Fetch all un-enhanced articles from the Laravel API
2. For each article:
   - Search the article title on Google
   - Scrape content from the top 2 ranking articles
   - Send original + references to Groq AI (Llama 3.3 70B)
   - Get AI-enhanced content
   - Update the article via Laravel API
   - Add reference citations

**Note**: This process takes 2-5 minutes depending on the number of articles.

### Step 3: View Articles

- Click on any article card to view details
- If enhanced, toggle between "Original" and "AI Enhanced" versions
- View reference sources at the bottom of enhanced articles
- Filter articles by "All", "Enhanced", or "Original"

---

## ðŸ”Œ API Endpoints

### Articles

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/articles` | Get all articles |
| GET | `/api/articles/{id}` | Get single article |
| POST | `/api/articles` | Create new article |
| PUT | `/api/articles/{id}` | Update article |
| DELETE | `/api/articles/{id}` | Delete article |
| POST | `/api/articles/scrape` | Trigger web scraping |

### Example API Requests

```bash
# Get all articles
curl http://127.0.0.1:8000/api/articles

# Trigger scraping
curl -X POST http://127.0.0.1:8000/api/articles/scrape

# Get single article
curl http://127.0.0.1:8000/api/articles/1

# Update article
curl -X PUT http://127.0.0.1:8000/api/articles/1 \
  -H "Content-Type: application/json" \
  -d '{"is_updated": true, "updated_content": "Enhanced content"}'
```

---

## ðŸ“ Project Structure

```
beyond-blogs/
â”œâ”€â”€ backend/                    # Laravel Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ Http/
â”‚   â”‚   â”‚   â””â”€â”€ Controllers/
â”‚   â”‚   â”‚       â””â”€â”€ ArticleController.php
â”‚   â”‚   â”œâ”€â”€ Models/
â”‚   â”‚   â”‚   â””â”€â”€ Article.php
â”‚   â”‚   â””â”€â”€ Services/
â”‚   â”‚       â””â”€â”€ ScraperService.php
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ migrations/
â”‚   â”‚   â”‚   â””â”€â”€ 2025_12_29_052738_create_articles_table.php
â”‚   â”‚   â””â”€â”€ database.sqlite
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ api.php
â”‚   â”œâ”€â”€ bootstrap/
â”‚   â”‚   â””â”€â”€ app.php
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ composer.json
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ enhancement-script/         # Node.js Enhancement Bot
â”‚   â”œâ”€â”€ enhancer.js
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ frontend/                   # React Frontend
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js
â”‚   â”‚   â”œâ”€â”€ index.js
â”‚   â”‚   â””â”€â”€ index.css
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â”œâ”€â”€ postcss.config.js
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                   # This file
```

---

## âœ¨ Features Implemented

### Phase 1: Web Scraping & CRUD APIs âœ…
- [x] Web scraping with Symfony HTTP Client
- [x] Navigate to last page of blog
- [x] Extract 5 oldest articles
- [x] SQLite database integration
- [x] Complete RESTful CRUD API
- [x] Structured JSON responses
- [x] Error handling with fallback sample articles

### Phase 2: AI Enhancement âœ…
- [x] Node.js-based enhancement script
- [x] Fetch articles from Laravel API
- [x] Google search automation
- [x] Scrape top 2 ranking articles
- [x] Groq AI (Llama 3.3 70B) integration
- [x] Content enhancement with context
- [x] Reference citation system
- [x] Update articles via API
- [x] Rate limiting and error handling

### Phase 3: React Frontend âœ…
- [x] Modern React 18 application
- [x] Responsive design (mobile-friendly)
- [x] Article dashboard with cards
- [x] Statistics display
- [x] Filter system (All/Enhanced/Original)
- [x] Article detail modal
- [x] Original vs Enhanced toggle
- [x] Reference links display
- [x] Loading states
- [x] Error handling
- [x] Professional UI/UX with Tailwind CSS
- [x] Gradient backgrounds and animations

---

## ðŸŽ¨ UI/UX Highlights

- **Modern Design**: Gradient backgrounds and smooth transitions
- **Card-Based Layout**: Clean article cards with hover effects
- **Responsive**: Works perfectly on mobile, tablet, and desktop
- **Interactive Stats**: Real-time article statistics with color coding
- **Modal View**: Full-screen article reading experience
- **Toggle System**: Easy switch between original and enhanced content
- **Reference Display**: Clean presentation of source articles
- **Loading States**: Smooth loading indicators and spinners
- **Color Coding**: Blue for total, green for enhanced, orange for pending

---

## ðŸŒ Deployment

### Backend (Railway / Render)

**Railway (Recommended)**:

1. Install Railway CLI: `npm install -g @railway/cli`
2. Login: `railway login`
3. Initialize: `railway init`
4. Add environment variables in Railway dashboard:
   - `APP_KEY` (from your .env)
   - `DB_CONNECTION=sqlite`
5. Deploy: `railway up`

### Frontend (Vercel)

1. Install Vercel CLI: `npm install -g vercel`
2. Deploy: `cd frontend && vercel`
3. Update API_URL in `src/App.js` to your Railway URL
4. Redeploy: `vercel --prod`

### Enhancement Script

Run manually or schedule with cron/GitHub Actions

---

## ðŸ› Troubleshooting

### Issue: PHP SQLite extension not found
**Solution**: Enable `extension=pdo_sqlite` and `extension=sqlite3` in `php.ini`

### Issue: Scraping returns no results
**Solution**: The scraper includes fallback sample articles if the website structure changes

### Issue: Tailwind CSS not working
**Solution**: Make sure you have Tailwind v3 installed: `npm install -D tailwindcss@3.4.1`

### Issue: Groq API rate limit
**Solution**: Groq has generous free tier limits. Add delays between requests if needed

### Issue: CORS errors
**Solution**: Ensure `bootstrap/app.php` has CORS middleware configured

---

## ðŸ“ Development Timeline

This project was developed over 3 days with frequent commits:

- **Day 1**: Laravel backend setup, database, CRUD APIs, web scraping with Symfony
- **Day 2**: Node.js enhancement script, Google search, Groq AI integration
- **Day 3**: React frontend, UI/UX with Tailwind, testing, documentation

See commit history for detailed development journey.

---

## ðŸ”‘ Why Groq Instead of OpenAI?

This project uses **Groq** instead of OpenAI for several reasons:

1. **FREE**: No credit card required, generous free tier
2. **Fast**: Extremely fast inference speeds
3. **Open Source Models**: Uses Llama 3.3 70B
4. **Same API Format**: Compatible with OpenAI SDK
5. **Great for Development**: Perfect for learning and prototyping

To switch to OpenAI later, simply:
1. Get OpenAI API key
2. Update `.env`: `OPENAI_API_KEY=sk-...`
3. Update `enhancer.js`: Remove `baseURL` and change model to `gpt-3.5-turbo`

---

## ðŸ“„ License

This project is open source and available under the [MIT License](LICENSE).

---

## ðŸ¤ Acknowledgments

- **BeyondChats** - For providing this challenging assignment
- **Groq** - For free, fast AI API
- **Laravel Community** - For excellent documentation
- **React Team** - For the amazing framework
- **Tailwind CSS** - For beautiful, utility-first styling

---

## ðŸ‘¤ Author

**Sahil Rafiq**
- Email: sahilrafiq479@gmail.com
- GitHub: [@sahilrafiq](https://github.com/sahilrafiq)
- LinkedIn: [Sahil Rafiq](https://www.linkedin.com/in/sahil-rafiq)


---

**â­ If you found this project interesting, please consider giving it a star!**

---

*Built with â¤ï¸ by Sahil Rafiq*